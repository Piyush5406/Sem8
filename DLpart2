from keras.datasets import imdb # Load the data, keeping only 10,000 of the most frequently occuring words
(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words = 10000)
-------------------------------------------------
word_index = imdb.get_word_index()
reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])
decoded_review = ' '.join([reverse_word_index.get(i-3, '?') for i in train_data[0]])
-------------------------------------------------------
import numpy as np

def vectorize_sequences(sequences, dimension=10000):
    results = np.zeros((len(sequences), dimension))    # Creates an all zero matrix of shape (len(sequences),10K)
    for i,sequence in enumerate(sequences):
        results[i,sequence] = 1                        # Sets specific indices of results[i] to 1s
    return results

# Vectorize training Data
X_train = vectorize_sequences(train_data)

# Vectorize testing Data
X_test = vectorize_sequences(test_data)
-------------------------------------------------------
class_names = ['negative','positive']
--------------------------------------
y_train = np.asarray(train_labels).astype('float32')
y_test  = np.asarray(test_labels).astype('float32')
---------------------------------------
y_test
-------------------------------------
from keras import models 
from keras import layers 
model = models.Sequential() 
model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))
model.add(layers.Dense(16, activation='relu')) 
model.add(layers.Dense(1, activation='sigmoid'))
------------------------------
from keras import optimizers
from keras import losses 
from keras import metrics 
model.compile(optimizer=optimizers.RMSprop(learning_rate=0.001), loss = losses.binary_crossentropy, metrics = [metrics.binary_accuracy])
-----------------------------
X_val = X_train[:10000]
partial_X_train = X_train[10000:] # Labels for validation 
y_val = y_train[:10000] 
partial_y_train = y_train[10000:]
-------------------------------
history = model.fit(partial_X_train, partial_y_train, epochs=10, batch_size=512, validation_data=(X_val, y_val))
---------------------------------
print(X_test[19])
----------------------------
# Making Predictions for testing data np.set_printoptions(suppress=True) 
import numpy as np

result = model.predict(np.expand_dims(X_test[19],axis=0))
print(result,class_names[int(result[0]>0.5)])
--------------------------------
print(X_test[0])
-----------------------------
ik = 123
print(train_data[ik])
print(train_labels[ik])
for i in train_data[ik]:
    print(list(word_index.keys())[list(word_index.values()).index(i)],end=" ")
---------------------------------
user = []

dyna = input("Enter: ").split(",")
for x in dyna:
    user.append(int(x))

user=vectorize_sequences(user)
result1 = model.predict(np.expand_dims(user[1],axis=0))
print()
print(result1,class_names[int(result1[0]>0.5)])
--------------------------------
#Enter: 1, 13, 92, 124, 51, 12, 9, 13, 169, 38, 3308, 44, 14, 22, 21, 4, 86, 58, 13, 219, 12, 13, 473, 8, 67, 89, 12, 1054, 146, 24, 6, 194, 337, 7, 723, 2, 885, 7, 325, 3287, 21, 13, 16, 371, 1535, 43, 89, 5, 54, 2, 62, 169, 27, 506, 32, 29, 694, 9, 15, 4, 430, 47, 1419, 523, 882, 30, 579, 13, 28, 24, 110, 14, 20, 11, 153, 885, 47, 12, 77, 617, 23, 248, 11, 6, 137, 21, 14, 20, 9, 643, 7, 31, 1601, 6761, 103, 4, 7154, 7, 325, 2, 287, 6, 55, 2259, 5, 483, 4051, 1146, 7, 6, 132, 416, 34, 27, 1883, 50, 9, 35, 5029, 749, 11, 14, 20, 15, 29, 9, 267, 18, 4, 236, 7778, 7, 406, 3696, 11, 4, 7032, 7, 14, 325, 5, 4, 635, 15, 29, 127, 6275, 138, 14, 20, 9, 24, 246, 23, 288, 42, 374, 9, 6, 736, 8, 72

-------------------------------------
get_phrase = input("Enter: ")

vec_words = []

for i in get_phrase.split(" "):
    vec_words.append(word_index[i.lower()])
    
vec_words = vectorize_sequences(vec_words)
result = []
#print(vec_words)
for j in range(len(vec_words)):
    result99 = model.predict(np.expand_dims(vec_words[j],axis=0))
    #print(result99[0],class_names[int(result99[0]>0.5)])
    result.append(class_names[int(result99[0]>0.5)])


if result.count('negative')> result.count('positive'):
    print("NEGATIVE")
else:
    print("POSITIVE")
-------------------------------------------
import tkinter as tk
import numpy as np

# Function to handle button click
def display_name_and_predict():
    # Get the name from the input field
    name = entry.get()   
    
    vec_words = []
    review_result = []

    for i in name.split(" "):
        vec_words.append(word_index[i.lower()])

    vec_words = vectorize_sequences(vec_words)
    result = []
    #print(vec_words)
    for j in range(len(vec_words)):
        result99 = model.predict(np.expand_dims(vec_words[j],axis=0))
        #print(result99[0],class_names[int(result99[0]>0.5)])
        result.append(result99[0][0])
        review_result.append(class_names[int(result99[0]>0.5)])

    mean = sum(result)/len(result)
    print(review_result)
    final = ''
    if review_result.count('negative')> review_result.count('positive'):
        final = "NEGATIVE"
    else:
        final = "POSITIVE"
    
    # Display the name on the label
    label.config(text=f"Comment is {round(mean,3)}% {final}!")

# Create the main window
window = tk.Tk()
window.title("Name Display and Prediction App")

# Create an input field
entry = tk.Entry(window, width=30)
entry.pack(pady=10)

# Create a button
button = tk.Button(window, text="Predict", command=display_name_and_predict)
button.pack(pady=10)

# Create a display label
label = tk.Label(window, text="")
label.pack(pady=10)

# Run the Tkinter event loop
window.mainloop()
-----------------------
